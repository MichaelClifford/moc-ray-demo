{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray with TensorFlow Test Notebook\n",
    "\n",
    "The purpose of this notebook is to confirm that Ray Train with TensorFlow works in ODH.\n",
    "\n",
    "This notebook primarily consists of an implementation of the TensorFlowlow example from the Ray docs on [Ray Train](https://docs.ray.io/en/latest/train/train.html). \n",
    "\n",
    "However, it has been modified to test that the Ray Train features for TensorFlow work in an Open Data Hub environment. We have also increased the number of samples and epochs run so that the speed up from Ray's distribution can be seen clearly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 20:45:29.830803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 20:45:29.830884: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import json\n",
    "import os\n",
    "\n",
    "import ray\n",
    "from ray.util import connect as ray_connect\n",
    "from ray.util import disconnect as ray_disconnect\n",
    "from ray.util.client import ray as rayclient\n",
    "from ray.train import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We're going to connect to our Ray Cluster that was spun up for us as part of the [ray notebook image](https://github.com/thoth-station/ray-ml-notebook) we selected through the ODH spawner page. \n",
    "\n",
    "This cell should also run locally without a Ray cluster as it checks for the relevant environment variable \"RAY_CLUSTER\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to ray-cluster-michaelclifford-ray-head\n"
     ]
    }
   ],
   "source": [
    "if os.environ.get('RAY_CLUSTER') is not None:\n",
    "    if rayclient.is_connected():\n",
    "        ray_disconnect()\n",
    "\n",
    "    ray_connect('{ray_head}:10001'.format(ray_head=os.environ['RAY_CLUSTER']))\n",
    "    print(f\"connected to {os.environ.get('RAY_CLUSTER')}\") \n",
    "else:\n",
    "    print(\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our data and model architecture\n",
    "\n",
    "For this example we will be using the well known MNIST character recognition dataset to train a classification model using a convolutional deep neural network (2 layers). However, for this particular notebook, we don't really care about the particular dataset or machine learning task. The goal here is to prove that our open data hub deployment can run Ray Train jobs with TensorFlow.\n",
    "\n",
    "First thing we will do is create a function that returns a TensorFlow Dataset object from the mnist dataset provided by tensorflow. We can use this Dataset object to iterate over batches of data during training. \n",
    "\n",
    "Next we'll define our TensorFlow model. This will be a convolutional neural network with 2 hidden layers, a 2D convolutional later, and a Dense layer. The model will taken in a 28 x 28 array and out put a 1 x 10 array representing the 10 possible categorize of digits our model will choose between.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(batch_size):\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (x_train, y_train)).shuffle(6000).repeat().batch(batch_size)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def build_and_compile_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Distributed Training \n",
    "\n",
    "Before we look at Ray and it's distributed training, let's start by training a single worker model here first to give us a baseline and something compare our distributed model to in a minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func():\n",
    "    batch_size = 64\n",
    "    single_worker_dataset = mnist_dataset(batch_size)\n",
    "    single_worker_model = build_and_compile_cnn_model()\n",
    "    single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 20:45:39.141525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-08 20:45:39.141615: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-08 20:45:39.141700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyterhub-nb-michaelclifford): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 20:45:40.578771: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 6s 69ms/step - loss: 2.2813 - accuracy: 0.1431\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 5s 67ms/step - loss: 2.2389 - accuracy: 0.3509\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 5s 68ms/step - loss: 2.1946 - accuracy: 0.4728\n",
      "CPU times: user 40.4 s, sys: 4.24 s, total: 44.7 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training\n",
    "\n",
    "Great, now let's re-write our training function a bit so that it's compatible with Ray Train. To update this function we need to:\n",
    "* Add `TF_CONFIG` environment variable that ray we handle for use\n",
    "* Add `num_workers` defined as the length of workers in tf_config\n",
    "* Set the distributed learning strategy as MultiWorkerMirroredStrategy\n",
    "* Add a `global_batch_size`\n",
    "* Add a `with strategy.scope()` statement to place our model building step \n",
    "* Finally, add a `ray.train.save_checkpoint` so that we can use our trained model for inference later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_distributed():\n",
    "    per_worker_batch_size = 64\n",
    "    # This environment variable will be set by Ray Train.\n",
    "    tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "    num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_and_compile_cnn_model()\n",
    "\n",
    "    multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70, verbose=0)\n",
    "    ray.train.save_checkpoint(epoch=2, model_weights=multi_worker_model.get_weights()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate our Ray `Trainer` that we use to manage which backend we want (pytorch, tensorflow or horovod) and the number of workers we will want to use. Below we will use 2 workers. Here we can also define whether or not we want to use a gpu for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 20:45:55,326\tINFO trainer.py:223 -- Trainer logs will be logged in: /opt/app-root/src/ray_results/train_2022-07-08_20-45-55\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(backend='tensorflow', num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Let's run our training function and see how long it takes with Ray Train's distribution functionality. Please note, there is an overhead cost associated with starting the Trainer. So let's time that separately from our actual training function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BackendExecutor pid=7544)\u001b[0m 2022-07-08 20:46:04.005542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BackendExecutor pid=7544)\u001b[0m 2022-07-08 20:46:04.005656: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:08.615363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:08.615462: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:08.662862: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:08.662960: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 ms, sys: 35.7 ms, total: 71.7 ms\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 20:46:10,382\tINFO trainer.py:229 -- Run results will be logged in: /opt/app-root/src/ray_results/train_2022-07-08_20-45-55/run_001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:10.481991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:10.482072: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:10.482118: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ray-cluster-michaelclifford-ray-cluster-michaelclifford-wov2drr): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:10.482006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:10.482090: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:10.482140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ray-cluster-michaelclifford-ray-cluster-michaelclifford-hef8zhz): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:10.508611: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.129.12.221:45339, 1 -> 10.129.12.234:50551}\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:10.514164: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:427] Started server with target: grpc://10.129.12.221:45339\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:10.508608: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.129.12.221:45339, 1 -> 10.129.12.234:50551}\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:10.514089: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:427] Started server with target: grpc://10.129.12.234:50551\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:13.375821: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m input: \"Placeholder/_1\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m       type: DT_FLOAT\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m       type: DT_INT64\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:13.340635: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m input: \"Placeholder/_1\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m       type: DT_FLOAT\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m       type: DT_INT64\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:13.887377: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=584, ip=10.129.12.234)\u001b[0m 2022-07-08 20:46:13.897382: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:13.985399: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=7583)\u001b[0m 2022-07-08 20:46:13.993566: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 225 ms, sys: 454 ms, total: 679 ms\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = trainer.run(train_func_distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times will vary depending on where you are running this notebook, the sample size you selected above, the number of epochs and the number of workers, but if everything worked correctly and you are using a distributed ray cluster, the Wall time for the `train.run()` function above should be significantly less than that for the non-distributed training run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 ms, sys: 5.09 ms, total: 9.8 ms\n",
      "Wall time: 749 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We've trained a model! Now we need to make sure we can use it for inference. Below we'll perform to quick examples of using the trained model. First, we'll generate a brand new data set the same way we did above, and use accuracy and sparse categorical cross entropy loss (same evaluation makes from training) to evaluate the model's performance on a new batch of 64 inputs.\n",
    "\n",
    "We are not particularly concerned about the values here, but are simply illustrating that we can perform inference with our newly trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = build_and_compile_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.set_weights(results[\"model_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = mnist_dataset(64)\n",
    "ds = ds.take(1)\n",
    "for i in ds:\n",
    "    ds = i\n",
    "X = ds[0]\n",
    "y = ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step - loss: 2.2233 - accuracy: 0.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2232537269592285, 0.359375]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are reading this cell and there are no errors above, then you have successfully run a Ray Train TensorFlow notebook in a distributed environment with Open Data Hub!  Yeahh!! :) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e34450d332bd313b8f818cb5ed04e25933b13de9c0d7b662ddcaf48d79a536f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
